"""Enhanced vulnerability checker service using PostgreSQL OVAL tables."""

import json
import os
import re
import logging
from typing import Dict, List, Set, Optional
from packaging import version
from sqlalchemy.orm import Session
from sqlalchemy import text
from datetime import datetime, timezone
from ..models.base import get_db
from ..models.nvd_cve_cache import NVDCVECache

logger = logging.getLogger(__name__)

# Import unified security services
try:
    from .unified_debian_security import unified_debian_security
    DEBIAN_LOOKUP_AVAILABLE = True
except ImportError:
    logger.warning("Unified Debian Security not available")
    DEBIAN_LOOKUP_AVAILABLE = False

try:
    from .unified_ubuntu_security import unified_ubuntu_security_schema
    UBUNTU_LOOKUP_AVAILABLE = True
    logger.info("Using Schema-Based OVAL Engine for Ubuntu vulnerability lookups")
except ImportError:
    logger.warning("Unified Ubuntu Security not available")
    UBUNTU_LOOKUP_AVAILABLE = False


class EnhancedVulnerabilityCheckerPG:
    """Enhanced vulnerability checker using PostgreSQL OVAL tables."""

    def __init__(self):
        """Initialize the PostgreSQL-based vulnerability checker."""
        logger.info("Enhanced Vulnerability Checker (PostgreSQL) initialized")

    def get_installed_packages(self, vuls_result_file: str) -> Dict[str, str]:
        """Extract installed packages from Vuls scan result."""
        try:
            if not os.path.exists(vuls_result_file):
                logger.error(f"Vuls result file not found: {vuls_result_file}")
                return {}

            logger.info(f"Reading Vuls result file: {vuls_result_file}")

            try:
                with open(vuls_result_file, "r") as f:
                    data = json.load(f)
            except PermissionError as pe:
                logger.error(f"Permission denied reading Vuls result file {vuls_result_file}: {pe}")
                return {}

            packages = {}

            # Handle both single server and multiple server formats
            if isinstance(data, dict):
                # Check if this is a direct server data or contains servers
                if "packages" in data:
                    # Direct server data
                    for pkg_name, pkg_info in data.get("packages", {}).items():
                        version = pkg_info.get("version", "")
                        packages[pkg_name] = version
                else:
                    # Multiple servers format - check each key for server data
                    for server_name, server_data in data.items():
                        if isinstance(server_data, dict) and "packages" in server_data:
                            for pkg_name, pkg_info in server_data.get("packages", {}).items():
                                version = pkg_info.get("version", "")
                                packages[pkg_name] = version

            logger.info(f"Extracted {len(packages)} packages from Vuls result")
            return packages

        except Exception as e:
            logger.error(f"Error reading Vuls result file {vuls_result_file}: {e}")
            return {}

    def identify_vulnerable_packages(self, all_packages: Dict[str, str]) -> Set[str]:
        """Dynamically identify packages that commonly have vulnerabilities."""

        # Always scan these critical packages (if installed)
        critical_packages = {
            "openssl", "openssh-server", "openssh-client", "sudo", "systemd",
            "libc6", "libc-bin", "glibc", "bash", "curl", "wget", "git",
            "perl", "python3", "python", "libxml2", "expat", "libexpat1"
        }

        # High-risk package patterns
        high_risk_patterns = [
            # Network/Web/Security
            (r".*ssh.*", "SSH-related"),
            (r".*ssl.*", "SSL/TLS libraries"),
            (r".*tls.*", "TLS libraries"),
            (r".*crypto.*", "Cryptographic libraries"),
            (r".*crypt.*", "Cryptographic libraries"),
            (r".*http.*", "HTTP libraries"),
            (r".*curl.*", "HTTP clients"),
            (r".*wget.*", "HTTP clients"),
            (r".*nginx.*", "Web servers"),
            (r".*apache.*", "Web servers"),
            # Languages/Runtimes
            (r".*java.*", "Java runtime"),
            (r".*python.*", "Python runtime"),
            (r".*perl.*", "Perl runtime"),
            (r".*php.*", "PHP runtime"),
            (r".*ruby.*", "Ruby runtime"),
            (r".*node.*", "Node.js runtime"),
            # Parsers/Libraries (often vulnerable)
            (r".*xml.*", "XML parsers"),
            (r".*json.*", "JSON parsers"),
            (r".*yaml.*", "YAML parsers"),
            (r".*expat.*", "XML parser"),
            (r".*libxml.*", "XML library"),
            (r".*parser.*", "Parser libraries"),
            # Archive/Compression
            (r".*zip.*", "Archive libraries"),
            (r".*tar.*", "Archive tools"),
            (r".*gzip.*", "Compression"),
            (r".*bzip.*", "Compression"),
            (r".*xz.*", "Compression"),
        ]

        vulnerable_packages = set(critical_packages)

        # Add packages matching high-risk patterns
        for pkg_name in all_packages.keys():
            for pattern, category in high_risk_patterns:
                if re.match(pattern, pkg_name, re.IGNORECASE):
                    vulnerable_packages.add(pkg_name)
                    logger.debug(f"Added {pkg_name} (matched {category})")
                    break

        # Filter to only packages that are actually installed
        installed_vulnerable = {
            pkg for pkg in vulnerable_packages if pkg in all_packages
        }

        logger.info(
            f"Identified {len(installed_vulnerable)} potentially vulnerable packages out of {len(all_packages)} total"
        )

        return installed_vulnerable

    def check_enhanced_vulnerabilities(self, all_packages: Dict[str, str],
                                     detected_os: str = None) -> List[Dict]:
        """Check vulnerabilities using PostgreSQL OVAL tables."""

        # Identify packages to scan
        packages_to_scan = self.identify_vulnerable_packages(all_packages)

        logger.info(f"Scanning {len(packages_to_scan)} potentially vulnerable packages using PostgreSQL OVAL...")

        vulnerabilities = []

        # Detect OS if not provided
        if not detected_os:
            detected_os = self._detect_os_from_packages(all_packages)

        logger.info(f"Detected OS: {detected_os}")

        # Check Ubuntu OVAL data
        if detected_os in ['ubuntu', 'unknown']:
            ubuntu_vulns = self._check_ubuntu_oval_vulnerabilities(packages_to_scan, all_packages)
            vulnerabilities.extend(ubuntu_vulns)
            logger.info(f"Found {len(ubuntu_vulns)} vulnerabilities from Ubuntu OVAL")

        # Check Debian OVAL data
        if detected_os in ['debian', 'unknown']:
            debian_vulns = self._check_debian_oval_vulnerabilities(packages_to_scan, all_packages)
            vulnerabilities.extend(debian_vulns)
            logger.info(f"Found {len(debian_vulns)} vulnerabilities from Debian OVAL")

        # Enhance with unified security services
        enhanced_vulnerabilities = []
        for vuln in vulnerabilities:
            enhanced_vuln = self._enhance_vulnerability_with_unified_services(vuln, detected_os)
            enhanced_vulnerabilities.append(enhanced_vuln)

        # Deduplicate vulnerabilities (same CVE for same package)
        deduplicated = self._deduplicate_vulnerabilities(enhanced_vulnerabilities)
        logger.info(f"After deduplication: {len(deduplicated)} unique vulnerabilities")

        # Enrich with NVD CVE data for CVSS scores and severity
        nvd_enriched = self._enrich_with_nvd_cve_data(deduplicated)
        logger.info(f"After NVD enrichment: {len(nvd_enriched)} vulnerabilities with enhanced CVSS data")

        return nvd_enriched

    def _detect_os_from_packages(self, all_packages: Dict[str, str]) -> str:
        """Detect OS from package versions."""
        # Check for Debian-specific version patterns
        for pkg_name, pkg_version in all_packages.items():
            if '+deb' in pkg_version:
                if '+deb12' in pkg_version or 'bookworm' in pkg_version:
                    return 'debian'
                elif '+deb11' in pkg_version or 'bullseye' in pkg_version:
                    return 'debian'
                elif '+deb10' in pkg_version or 'buster' in pkg_version:
                    return 'debian'
                else:
                    return 'debian'

            # Check for Ubuntu-specific version patterns
            if 'ubuntu' in pkg_version.lower():
                return 'ubuntu'
            if any(x in pkg_version for x in ['~22.04', '~20.04', '~18.04', '~16.04']):
                return 'ubuntu'

        return 'unknown'

    def _check_ubuntu_oval_vulnerabilities(self, packages_to_scan: Set[str],
                                         all_packages: Dict[str, str]) -> List[Dict]:
        """Check vulnerabilities using Ubuntu unified security service (schema-based OVAL)."""
        vulnerabilities = []

        if not UBUNTU_LOOKUP_AVAILABLE:
            logger.warning("Ubuntu unified security service not available")
            return vulnerabilities

        try:
            for package_name in sorted(packages_to_scan):
                if package_name in all_packages:
                    installed_version = all_packages[package_name]
                    release = self._detect_ubuntu_release(installed_version)

                    # Use unified security service to get package vulnerabilities
                    try:
                        package_vulns = unified_ubuntu_security_schema.get_package_vulnerabilities(
                            package_name, release
                        )

                        # Process vulnerabilities from unified service
                        combined_vulns = package_vulns.get('combined', [])

                        for vuln_data in combined_vulns:
                            cve_id = vuln_data.get('cve_id')
                            if not cve_id or not cve_id.startswith('CVE-'):
                                continue

                            # Skip old CVEs to reduce noise
                            if not self._is_recent_cve(cve_id):
                                continue

                            # Check if this version is actually vulnerable
                            fixed_version = vuln_data.get('fixed_version')
                            not_fixed_yet = vuln_data.get('not_fixed_yet', False)

                            if not self._is_version_vulnerable(installed_version, fixed_version, not_fixed_yet):
                                continue

                            vulnerability = {
                                "cve_id": cve_id,
                                "source": "Ubuntu Schema-Based OVAL",
                                "definition_id": vuln_data.get('definition_id'),
                                "title": vuln_data.get('title', f"{cve_id} vulnerability"),
                                "description": vuln_data.get('description', ''),
                                "severity": vuln_data.get('severity', 'unknown'),
                                "cvss_score": self._map_severity_to_cvss(vuln_data.get('severity')),
                                "affected_package": package_name,
                                "installed_version": installed_version,
                                "fixed_version": fixed_version,
                                "not_fixed_yet": not_fixed_yet,
                                "release": release,
                                "os_type": "ubuntu",
                                "confidence_score": vuln_data.get('confidence_score', 0.95)
                            }

                            vulnerabilities.append(vulnerability)

                    except Exception as e:
                        logger.warning(f"Error checking {package_name} with unified service: {e}")
                        continue

        except Exception as e:
            logger.error(f"Error checking Ubuntu OVAL vulnerabilities: {e}")

        return vulnerabilities

    def _check_debian_oval_vulnerabilities(self, packages_to_scan: Set[str],
                                         all_packages: Dict[str, str]) -> List[Dict]:
        """Check vulnerabilities using Debian OVAL PostgreSQL tables."""
        vulnerabilities = []

        try:
            db = next(get_db())

            for package_name in sorted(packages_to_scan):
                if package_name in all_packages:
                    installed_version = all_packages[package_name]

                    # Detect Debian release
                    release = self._detect_debian_release(installed_version)

                    # Query Debian OVAL data
                    result = db.execute(text("""
                        SELECT DISTINCT
                            d.definition_id,
                            d.title,
                            d.description,
                            d.severity,
                            p.version as fixed_version,
                            p.not_fixed_yet,
                            r.ref_id as cve_id
                        FROM debian_oval_definitions d
                        JOIN debian_oval_packages p ON d.id = p.definition_id
                        JOIN debian_oval_references r ON d.id = r.definition_id
                        WHERE p.package_name = :package_name
                        AND d.release_version = :release
                        AND r.ref_id LIKE 'CVE-%'
                        ORDER BY r.ref_id DESC
                    """), {
                        'package_name': package_name,
                        'release': release
                    })

                    for row in result.fetchall():
                        definition_id, title, description, severity, fixed_version, not_fixed_yet, cve_id = row

                        # Skip old CVEs to reduce noise
                        if not self._is_recent_cve(cve_id):
                            continue

                        # Check if version is vulnerable
                        if not self._is_version_vulnerable(installed_version, fixed_version, not_fixed_yet):
                            continue

                        vulnerability = {
                            "cve_id": cve_id,
                            "source": "Debian OVAL",
                            "definition_id": definition_id,
                            "title": title,
                            "description": description or "",
                            "summary": description or "",  # Add summary field
                            "severity": severity or "unknown",  # Default to unknown if empty
                            "cvss_score": self._map_severity_to_cvss(severity),  # Add CVSS score mapping
                            "affected_package": package_name,
                            "installed_version": installed_version,
                            "fixed_version": fixed_version,
                            "not_fixed_yet": not_fixed_yet,
                            "release": release,
                            "os_type": "debian",
                            "confidence_score": 0.90,
                            "published_date": None,  # Could be extracted from metadata if needed
                            "priority": severity or "unknown"  # Map severity to priority
                        }

                        vulnerabilities.append(vulnerability)

        except Exception as e:
            logger.error(f"Error checking Debian OVAL vulnerabilities: {e}")
        finally:
            if 'db' in locals():
                db.close()

        return vulnerabilities

    def _detect_ubuntu_release(self, installed_version: str) -> str:
        """Detect Ubuntu release from package version."""
        if '~24.04' in installed_version or 'noble' in installed_version.lower():
            return '24.04'
        elif '~22.04' in installed_version or 'jammy' in installed_version.lower():
            return '22.04'
        elif '~20.04' in installed_version or 'focal' in installed_version.lower():
            return '20.04'
        elif '~18.04' in installed_version or 'bionic' in installed_version.lower():
            return '18.04'
        elif '~16.04' in installed_version or 'xenial' in installed_version.lower():
            return '16.04'
        else:
            return '22.04'  # Default to current LTS

    def _detect_debian_release(self, installed_version: str) -> str:
        """Detect Debian release from package version."""
        if '+deb12' in installed_version or 'bookworm' in installed_version.lower():
            return '12'
        elif '+deb11' in installed_version or 'bullseye' in installed_version.lower():
            return '11'
        elif '+deb10' in installed_version or 'buster' in installed_version.lower():
            return '10'
        elif '+deb9' in installed_version or 'stretch' in installed_version.lower():
            return '9'
        elif '+deb8' in installed_version or 'jessie' in installed_version.lower():
            return '8'
        elif '+deb7' in installed_version or 'wheezy' in installed_version.lower():
            return '7'
        else:
            return '12'  # Default to current stable

    def _is_recent_cve(self, cve_id: str) -> bool:
        """Check if CVE is recent enough to be relevant."""
        year_match = re.search(r"CVE-(\d{4})", cve_id)
        if year_match:
            cve_year = int(year_match.group(1))
            return cve_year >= 2018  # Only include CVEs from 2018 onwards
        return True

    def _is_version_vulnerable(self, installed_version: str, fixed_version: str,
                             not_fixed_yet: bool = False) -> bool:
        """Check if installed version is vulnerable."""
        # If not fixed yet, it's vulnerable
        if not_fixed_yet:
            return True

        # If no fixed version, assume vulnerable
        if not fixed_version:
            return True

        try:
            # Use Debian version comparison for proper handling
            comparison = self.compare_debian_versions(installed_version, fixed_version)
            return comparison < 0  # vulnerable if installed < fixed
        except Exception as e:
            logger.warning(f"Error comparing versions {installed_version} vs {fixed_version}: {e}")
            return True  # Default to vulnerable if can't compare

    def _enhance_vulnerability_with_unified_services(self, vulnerability: Dict,
                                                   detected_os: str) -> Dict:
        """Enhance vulnerability with unified security services."""
        cve_id = vulnerability.get("cve_id", "")
        package_name = vulnerability.get("affected_package", "")
        release = vulnerability.get("release", "")
        os_type = vulnerability.get("os_type", detected_os)

        enhanced = vulnerability.copy()

        # Enhance with Debian unified security if applicable
        if DEBIAN_LOOKUP_AVAILABLE and os_type == 'debian':
            try:
                debian_info = unified_debian_security.lookup_vulnerability(
                    cve_id, package_name, release
                )
                if debian_info and debian_info.get('combined', {}).get('found'):
                    combined = debian_info['combined']
                    enhanced.update({
                        'debian_status': combined.get('status'),
                        'debian_fixed_version': combined.get('fixed_version'),
                        'debian_urgency': combined.get('urgency'),
                        'enhanced_by_debian': True,
                        'confidence_score': max(enhanced.get('confidence_score', 0.8),
                                              combined.get('confidence_score', 0.8))
                    })
                    logger.debug(f"Enhanced {cve_id} with Debian unified data")
            except Exception as e:
                logger.warning(f"Error enhancing with Debian unified data: {e}")

        # Enhance with Ubuntu unified security if applicable
        if UBUNTU_LOOKUP_AVAILABLE and os_type == 'ubuntu':
            try:
                ubuntu_info = unified_ubuntu_security_schema.lookup_vulnerability(
                    cve_id, package_name, release
                )
                if ubuntu_info and ubuntu_info.get('combined', {}).get('found'):
                    combined = ubuntu_info['combined']
                    enhanced.update({
                        'ubuntu_status': combined.get('status'),
                        'ubuntu_fixed_version': combined.get('fixed_version'),
                        'ubuntu_priority': combined.get('priority'),
                        'enhanced_by_ubuntu': True,
                        'confidence_score': max(enhanced.get('confidence_score', 0.8),
                                              combined.get('confidence_score', 0.8))
                    })
                    logger.debug(f"Enhanced {cve_id} with Ubuntu unified data")
            except Exception as e:
                logger.warning(f"Error enhancing with Ubuntu unified data: {e}")

        return enhanced

    def _deduplicate_vulnerabilities(self, vulnerabilities: List[Dict]) -> List[Dict]:
        """Remove duplicate vulnerabilities."""
        seen = set()
        deduplicated = []

        for vuln in vulnerabilities:
            key = (vuln["cve_id"], vuln["affected_package"])

            if key not in seen:
                seen.add(key)
                deduplicated.append(vuln)
            else:
                # If we have a duplicate, prefer higher confidence source
                existing_idx = None
                for i, existing in enumerate(deduplicated):
                    if (existing["cve_id"], existing["affected_package"]) == key:
                        existing_idx = i
                        break

                if existing_idx is not None:
                    existing = deduplicated[existing_idx]
                    if vuln.get("confidence_score", 0) > existing.get("confidence_score", 0):
                        deduplicated[existing_idx] = vuln

        return deduplicated

    def _enrich_with_nvd_cve_data(self, vulnerabilities: List[Dict]) -> List[Dict]:
        """Enrich vulnerabilities with NVD CVE data for CVSS scores and severity."""
        enriched_vulnerabilities = []

        try:
            db = next(get_db())

            for vuln in vulnerabilities:
                cve_id = vuln.get('cve_id', '')
                if not cve_id or not cve_id.startswith('CVE-'):
                    enriched_vulnerabilities.append(vuln)
                    continue

                # Check if we already have good CVSS data
                if vuln.get('cvss_score') and vuln.get('cvss_score') > 0:
                    enriched_vulnerabilities.append(vuln)
                    continue

                # Look up CVE in cache first
                nvd_data = self._get_nvd_cve_data(cve_id, db)

                if nvd_data:
                    # Enrich vulnerability with NVD data
                    enriched_vuln = vuln.copy()
                    enriched_vuln.update({
                        'cvss_score': nvd_data.get_best_cvss_score(),
                        'cvss_vector': nvd_data.get_best_cvss_vector(),
                        'severity': nvd_data.get_best_severity(),
                        'cvss_version': nvd_data.get_cvss_version_used(),
                        'nvd_published_date': nvd_data.published_date.isoformat() if nvd_data.published_date else None,
                        'enhanced_by_nvd': True,
                        'confidence_score': max(vuln.get('confidence_score', 0.8), 0.9)
                    })

                    # Update summary if missing
                    if not enriched_vuln.get('summary') and nvd_data.description:
                        enriched_vuln['summary'] = nvd_data.description

                    # Update description if missing
                    if not enriched_vuln.get('description') and nvd_data.description:
                        enriched_vuln['description'] = nvd_data.description

                    logger.debug(f"Enriched {cve_id} with NVD data: CVSS {nvd_data.get_best_cvss_score()}")
                    enriched_vulnerabilities.append(enriched_vuln)
                else:
                    # No NVD data available, keep original
                    enriched_vulnerabilities.append(vuln)

        except Exception as e:
            logger.error(f"Error enriching vulnerabilities with NVD data: {e}")
            return vulnerabilities  # Return original on error
        finally:
            if 'db' in locals():
                db.close()

        return enriched_vulnerabilities

    def _get_nvd_cve_data(self, cve_id: str, db: Session) -> Optional[NVDCVECache]:
        """Get NVD CVE data from cache with optional fallback to API."""
        try:
            # Check cache first
            cached_cve = db.query(NVDCVECache).filter(NVDCVECache.cve_id == cve_id).first()

            if cached_cve:
                # Update access statistics
                cached_cve.update_access_stats()
                db.commit()
                logger.debug(f"Found cached NVD data for {cve_id}")
                return cached_cve

            # Not in cache - try fallback API call with proper rate limiting
            logger.debug(f"CVE {cve_id} not in cache, attempting fallback API call")
            nvd_data = self._fetch_cve_from_nvd_with_rate_limiting(cve_id)

            if nvd_data:
                # Cache the result
                cached_cve = self._cache_nvd_cve_data(cve_id, nvd_data, db)
                return cached_cve

            logger.debug(f"CVE {cve_id} not found in NVD or rate limited - will be fetched by scheduled update")
            return None

        except Exception as e:
            logger.error(f"Error getting NVD data for {cve_id}: {e}")
            return None

    def _fetch_cve_from_nvd_with_rate_limiting(self, cve_id: str) -> Optional[Dict]:
        """Fetch CVE data from NVD API with proper global rate limiting."""
        try:
            from .global_nvd_rate_limiter import global_nvd_rate_limiter
            from .nvd_cve_source import NVDCVESource

            # Check if we can make a request
            if not global_nvd_rate_limiter.can_make_request():
                # Try to wait for rate limit (max 30 seconds for real-time requests)
                if not global_nvd_rate_limiter.wait_for_rate_limit(timeout=30):
                    logger.info(f"Rate limit timeout for {cve_id}, skipping real-time fetch")
                    return None

            # Record that we're making a request
            global_nvd_rate_limiter.record_request()

            nvd_source = NVDCVESource()

            try:
                result = nvd_source.lookup_vulnerability_info(cve_id, "")

                if result and result.get('found'):
                    logger.info(f"Successfully fetched {cve_id} from NVD API")
                    return result
                elif result and not result.get('found'):
                    logger.debug(f"CVE {cve_id} not found in NVD")
                    return None

                return None

            except Exception as e:
                error_str = str(e).lower()

                # Handle rate limiting specifically
                if '429' in error_str or 'too many requests' in error_str:
                    global_nvd_rate_limiter.record_429_error()
                    logger.warning(f"Rate limited for {cve_id}, will be fetched by scheduled update")
                    return None
                else:
                    logger.error(f"Error fetching {cve_id} from NVD: {e}")
                    return None

        except Exception as e:
            logger.error(f"Error in rate-limited fetch for {cve_id}: {e}")
            return None

    def _fetch_cve_from_nvd(self, cve_id: str) -> Optional[Dict]:
        """Fetch CVE data from NVD API with rate limit handling."""
        try:
            from .nvd_cve_source import NVDCVESource
            import time
            import random

            nvd_source = NVDCVESource()

            # Implement exponential backoff for rate limiting
            max_retries = 3
            base_delay = 6  # NVD allows 5 requests per 30 seconds, so 6 second delay

            for attempt in range(max_retries):
                try:
                    result = nvd_source.lookup_vulnerability_info(cve_id, "")

                    if result and result.get('found'):
                        return result
                    elif result and not result.get('found'):
                        # CVE not found in NVD, don't retry
                        return None

                    return None

                except Exception as e:
                    error_str = str(e).lower()

                    # Handle rate limiting specifically
                    if '429' in error_str or 'too many requests' in error_str:
                        if attempt < max_retries - 1:
                            # Exponential backoff with jitter
                            delay = base_delay * (2 ** attempt) + random.uniform(0, 2)
                            logger.warning(f"Rate limited for {cve_id}, retrying in {delay:.1f}s (attempt {attempt + 1}/{max_retries})")
                            time.sleep(delay)
                            continue
                        else:
                            logger.warning(f"Rate limited for {cve_id}, max retries exceeded. Will try again later.")
                            return None
                    else:
                        # Other error, don't retry
                        logger.error(f"Error fetching {cve_id} from NVD: {e}")
                        return None

            return None

        except Exception as e:
            logger.error(f"Error fetching {cve_id} from NVD: {e}")
            return None

    def _cache_nvd_cve_data(self, cve_id: str, nvd_data: Dict, db: Session) -> Optional[NVDCVECache]:
        """Cache NVD CVE data in the database."""
        try:
            # Parse dates
            published_date = None
            last_modified_date = None

            if nvd_data.get('published'):
                try:
                    published_date = datetime.fromisoformat(nvd_data['published'].replace('Z', '+00:00'))
                except:
                    pass

            if nvd_data.get('last_modified'):
                try:
                    last_modified_date = datetime.fromisoformat(nvd_data['last_modified'].replace('Z', '+00:00'))
                except:
                    pass

            # Create cache entry
            cache_entry = NVDCVECache(
                cve_id=cve_id,
                description=nvd_data.get('description', ''),
                published_date=published_date,
                last_modified_date=last_modified_date,
                source_data=nvd_data,  # Store full response
                cached_at=datetime.now(timezone.utc),
                last_accessed=datetime.now(timezone.utc),
                access_count=1
            )

            # Extract CVSS data based on what's available
            cvss_score = nvd_data.get('cvss_score')
            cvss_vector = nvd_data.get('cvss_vector', '')
            severity = nvd_data.get('severity', '')

            # Determine CVSS version and populate appropriate fields
            if cvss_vector.startswith('CVSS:3.1/'):
                cache_entry.cvss_v31_score = cvss_score
                cache_entry.cvss_v31_vector = cvss_vector
                cache_entry.cvss_v31_severity = severity
            elif cvss_vector.startswith('CVSS:3.0/'):
                cache_entry.cvss_v30_score = cvss_score
                cache_entry.cvss_v30_vector = cvss_vector
                cache_entry.cvss_v30_severity = severity
            elif cvss_vector.startswith('AV:') or cvss_vector.startswith('(AV:'):
                # CVSS v2
                cache_entry.cvss_v2_score = cvss_score
                cache_entry.cvss_v2_vector = cvss_vector
                cache_entry.cvss_v2_severity = severity
            else:
                # Default to v3.1 if we can't determine
                cache_entry.cvss_v31_score = cvss_score
                cache_entry.cvss_v31_vector = cvss_vector
                cache_entry.cvss_v31_severity = severity

            db.add(cache_entry)
            db.commit()
            db.refresh(cache_entry)

            logger.info(f"Cached NVD data for {cve_id} with CVSS {cvss_score}")
            return cache_entry

        except Exception as e:
            logger.error(f"Error caching NVD data for {cve_id}: {e}")
            db.rollback()
            return None

    def parse_debian_version(self, version_str: str) -> Dict[str, str]:
        """Parse a Debian version string into its components."""
        if not version_str:
            return {"epoch": "", "upstream": "0", "debian": "", "build": ""}

        # Handle epoch (1:version)
        epoch = ""
        remaining = version_str
        if ":" in version_str:
            epoch, remaining = version_str.split(":", 1)

        # Handle build info (+deb12u12)
        build = ""
        if "+" in remaining:
            remaining, build = remaining.split("+", 1)

        # Handle debian revision (-10)
        debian = ""
        if "-" in remaining:
            upstream, debian = remaining.rsplit("-", 1)
        else:
            upstream = remaining

        # Clean upstream version
        upstream = self._clean_upstream_version(upstream)

        return {
            "epoch": epoch,
            "upstream": upstream,
            "debian": debian,
            "build": build
        }

    def _clean_upstream_version(self, version_str: str) -> str:
        """Clean upstream version for proper comparison."""
        if not version_str:
            return "0"

        # Handle pre-release versions with ~
        cleaned = version_str.replace("~", "")

        # Handle git snapshots
        cleaned = re.sub(r"~git(\d+)", r".git\1", cleaned)

        # Remove invalid characters but keep rc, a, b for pre-releases
        cleaned = re.sub(r"[^0-9.rcab]", "", cleaned)

        if not cleaned or cleaned == ".":
            return "0"

        return cleaned

    def compare_debian_versions(self, installed: str, fixed: str) -> int:
        """Compare two Debian version strings."""
        try:
            inst_parts = self.parse_debian_version(installed)
            fixed_parts = self.parse_debian_version(fixed)

            # Compare epoch first
            inst_epoch = int(inst_parts["epoch"]) if inst_parts["epoch"] else 0
            fixed_epoch = int(fixed_parts["epoch"]) if fixed_parts["epoch"] else 0

            if inst_epoch != fixed_epoch:
                return -1 if inst_epoch < fixed_epoch else 1

            # Compare upstream versions
            try:
                inst_upstream = version.parse(inst_parts["upstream"])
                fixed_upstream = version.parse(fixed_parts["upstream"])

                if inst_upstream != fixed_upstream:
                    return -1 if inst_upstream < fixed_upstream else 1
            except Exception:
                # Fall back to string comparison
                if inst_parts["upstream"] != fixed_parts["upstream"]:
                    return -1 if inst_parts["upstream"] < fixed_parts["upstream"] else 1

            # Compare Debian revisions
            if inst_parts["debian"] and fixed_parts["debian"]:
                # For Ubuntu packages, try to extract Ubuntu security numbers first
                inst_ubuntu_security = self._extract_ubuntu_security_number(inst_parts["debian"])
                fixed_ubuntu_security = self._extract_ubuntu_security_number(fixed_parts["debian"])

                if inst_ubuntu_security is not None and fixed_ubuntu_security is not None:
                    # Both have Ubuntu security numbers, compare them
                    if inst_ubuntu_security != fixed_ubuntu_security:
                        return -1 if inst_ubuntu_security < fixed_ubuntu_security else 1
                else:
                    # Fall back to regular debian revision comparison
                    try:
                        inst_debian = int(inst_parts["debian"])
                        fixed_debian = int(fixed_parts["debian"])

                        if inst_debian != fixed_debian:
                            return -1 if inst_debian < fixed_debian else 1
                    except ValueError:
                        if inst_parts["debian"] != fixed_parts["debian"]:
                            return -1 if inst_parts["debian"] < fixed_parts["debian"] else 1

            # Compare build info (security updates)
            if inst_parts["build"] and fixed_parts["build"]:
                inst_security = self._extract_security_update_number(inst_parts["build"])
                fixed_security = self._extract_security_update_number(fixed_parts["build"])

                if inst_security is not None and fixed_security is not None:
                    if inst_security != fixed_security:
                        return -1 if inst_security < fixed_security else 1

            return 0  # Versions are equal

        except Exception as e:
            logger.warning(f"Error comparing Debian versions {installed} vs {fixed}: {e}")
            return -1  # Default to vulnerable

    def _extract_security_update_number(self, build_info: str) -> Optional[int]:
        """Extract security update number from build info."""
        # For Ubuntu, look for ubuntu10.6 pattern in build info
        match = re.search(r"ubuntu(\d+)\.(\d+)", build_info)
        if match:
            # Convert ubuntu10.6 to a comparable number: 10 * 100 + 6 = 1006
            major = int(match.group(1))
            minor = int(match.group(2))
            return major * 100 + minor

        # For Debian, look for deb12u6 pattern
        match = re.search(r"deb\d+u(\d+)", build_info)
        if match:
            return int(match.group(1))

        return None

    def _extract_ubuntu_security_number(self, debian_revision: str) -> Optional[int]:
        """Extract Ubuntu security update number from debian revision field."""
        # For Ubuntu, look for 2ubuntu10.6 pattern in debian revision
        match = re.search(r"(\d+)ubuntu(\d+)\.(\d+)", debian_revision)
        if match:
            # Convert 2ubuntu10.6 to a comparable number: 10 * 100 + 6 = 1006
            # The first number (2) is the debian revision, ubuntu10.6 is the Ubuntu part
            ubuntu_major = int(match.group(2))
            ubuntu_minor = int(match.group(3))
            return ubuntu_major * 100 + ubuntu_minor

        return None

    def _map_severity_to_cvss(self, severity: str) -> Optional[float]:
        """Map Ubuntu/Debian severity levels to approximate CVSS scores."""
        if not severity:
            return None

        severity_lower = severity.lower().strip()

        # Ubuntu/Debian severity to CVSS mapping
        severity_mapping = {
            'critical': 9.0,
            'high': 7.5,
            'medium': 5.0,
            'low': 2.5,
            'negligible': 1.0,
            'unknown': None
        }

        return severity_mapping.get(severity_lower, None)

    def _create_vulnerability_title(self, cve_id: str, description: str, original_title: str) -> str:
        """Create a better vulnerability title from the description."""
        if not description:
            return original_title or f"{cve_id} vulnerability"

        # Extract the first sentence from the description as a better title
        sentences = description.split('. ')
        if sentences:
            first_sentence = sentences[0].strip()

            # Clean up the first sentence
            if first_sentence:
                # Remove "It was discovered that" prefix if present
                if first_sentence.lower().startswith('it was discovered that '):
                    first_sentence = first_sentence[23:]  # Remove "It was discovered that "
                    first_sentence = first_sentence[0].upper() + first_sentence[1:] if first_sentence else ""

                # Ensure it ends with a period
                if first_sentence and not first_sentence.endswith('.'):
                    first_sentence += '.'

                # Limit length to reasonable title size
                if len(first_sentence) > 120:
                    first_sentence = first_sentence[:117] + '...'

                return first_sentence

        # Fallback to original title if description parsing fails
        return original_title or f"{cve_id} vulnerability"

    def generate_enhanced_report(self, vulnerabilities: List[Dict]) -> Dict:
        """Generate enhanced vulnerability report."""
        if not vulnerabilities:
            return {
                "total_vulnerabilities": 0,
                "packages_affected": 0,
                "vulnerability_breakdown": {},
                "source_breakdown": {},
                "os_breakdown": {},
                "high_risk_packages": [],
                "vulnerabilities": [],
            }

        # Group by package, severity, source, and OS
        by_package = {}
        by_severity = {"CRITICAL": 0, "HIGH": 0, "MEDIUM": 0, "LOW": 0, "unknown": 0}
        by_source = {}
        by_os = {}

        for vuln in vulnerabilities:
            # By package
            pkg = vuln["affected_package"]
            if pkg not in by_package:
                by_package[pkg] = {
                    "total": 0,
                    "critical": 0,
                    "high": 0,
                    "medium": 0,
                    "low": 0,
                    "sources": set(),
                    "os_types": set(),
                }

            by_package[pkg]["total"] += 1
            severity = vuln.get("severity", "unknown").upper()

            # Map severity
            severity_mapping = {
                "CRITICAL": "critical",
                "HIGH": "high",
                "MEDIUM": "medium",
                "LOW": "low"
            }

            if severity in severity_mapping:
                by_package[pkg][severity_mapping[severity]] += 1

            # By severity
            if severity in by_severity:
                by_severity[severity] += 1
            else:
                by_severity["unknown"] += 1

            # By source
            source = vuln.get("source", "unknown")
            by_source[source] = by_source.get(source, 0) + 1
            by_package[pkg]["sources"].add(source)

            # By OS
            os_type = vuln.get("os_type", "unknown")
            by_os[os_type] = by_os.get(os_type, 0) + 1
            by_package[pkg]["os_types"].add(os_type)

        # Calculate risk scores
        high_risk_packages = []
        for pkg, counts in by_package.items():
            risk_score = (
                counts["critical"] * 20
                + counts["high"] * 10
                + counts["medium"] * 5
                + counts["low"] * 1
            )

            high_risk_packages.append({
                "package": pkg,
                "total_vulns": counts["total"],
                "critical": counts["critical"],
                "high": counts["high"],
                "medium": counts["medium"],
                "low": counts["low"],
                "sources": list(counts["sources"]),
                "os_types": list(counts["os_types"]),
                "risk_score": risk_score,
            })

        high_risk_packages.sort(key=lambda x: x["risk_score"], reverse=True)

        return {
            "total_vulnerabilities": len(vulnerabilities),
            "packages_affected": len(by_package),
            "vulnerability_breakdown": by_severity,
            "source_breakdown": by_source,
            "os_breakdown": by_os,
            "high_risk_packages": high_risk_packages,
            "vulnerabilities": vulnerabilities,
        }
